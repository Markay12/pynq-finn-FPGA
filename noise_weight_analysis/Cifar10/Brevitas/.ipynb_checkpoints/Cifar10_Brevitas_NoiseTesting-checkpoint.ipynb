{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d262029f",
   "metadata": {},
   "source": [
    "## Loading Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab45e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import os\n",
    "from unicodedata import decimal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# add imports for randomness\n",
    "import time\n",
    "import random\n",
    "\n",
    "import sys\n",
    "\n",
    "# Brevitas imports\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.quant import Int32Bias\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# For adaptive learning rate import\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import random_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b10c6b2",
   "metadata": {},
   "source": [
    "## Define Target Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b627c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Target device: \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb176a",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Define the train and validation set sizes. Split dataset into train and validation sets.\n",
    "\n",
    "Set the batch size. Create a dataloader for a training dataset with batch size of 1000.\n",
    "\n",
    "### Data Augmentation\n",
    "\n",
    "This code block applies data augmentation to the CIFAR-10 training dataset using transforms.RandomCrop and transforms.RandomHorizontalFlip. This randomly crops and flips the images in the dataset, which creates new variations of the original images. This technique is called data augmentation and can help prevent overfitting by increasing the diversity of the training dataset.\n",
    "\n",
    "Additionally, this code block also normalizes the pixel values of both the training and validation datasets to have a mean of 0.5 and a standard deviation of 0.5 using transforms.Normalize.\n",
    "\n",
    "Furthermore, the code block uses PyTorch DataLoader to create an iterator over the dataset that returns batches of data. This avoids the need for manual batch creation and helps to efficiently load and process the data.\n",
    "\n",
    "Finally, this code block creates a DataLoader for the training and validation datasets with a batch size of 1000. This means that the model will process 1000 images at a time during training and validation, which can help to speed up the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ae95b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "torch.Size([128, 3, 32, 32])\n",
      "50000\n",
      "Samples in each set: train = 50000, test = 391\n",
      "Shape of one input sample: torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define data augmentation transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Apply data augmentation to the training dataset\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "\n",
    "# Use the validation transform for the validation dataset\n",
    "val_set =torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=val_transform)\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "a = next(iter(train_loader))\n",
    "print(a[0].size())\n",
    "print(len(train_set))\n",
    "\n",
    "print(\"Samples in each set: train = %d, test = %s\" % (len(train_set), len(train_loader))) \n",
    "print(\"Shape of one input sample: \" +  str(train_set[0][0].shape))\n",
    "\n",
    "## Data Loader\n",
    "#\n",
    "# Using PyTorch dataloader we can create a convenient iterator over the dataset that returns batches of data, rather than requiring manual batch creation.\n",
    "\n",
    "# set batch size\n",
    "batch_size = 1000\n",
    "\n",
    "# Create a DataLoader for a training dataset with a batch size of 100\n",
    "train_quantized_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "test_quantized_loader = DataLoader(val_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4e5f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Shape:\n",
      "-------------------------\n",
      "Input shape for 1 batch: torch.Size([128, 3, 32, 32])\n",
      "Label shape for 1 batch: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "print(\"\\nDataset Shape:\\n-------------------------\")\n",
    "for x, y in train_loader:\n",
    "    print(\"Input shape for 1 batch: \" + str(x.shape))\n",
    "    print(\"Label shape for 1 batch: \" + str(y.shape))\n",
    "    count += 1\n",
    "    if count == 1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53010ed9",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "\n",
    "There are 5 convolution layers and 2 Fully Connected QuantLinear Layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "357e66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10CNN, self).__init__()\n",
    "        self.quant_inp = qnn.QuantIdentity(bit_width=4, return_quant_tensor=True)\n",
    "\n",
    "        self.layer1 = qnn.QuantConv2d(3, 32, 3, padding=1, bias=True, weight_bit_width=4, bias_quant=Int32Bias)\n",
    "        self.relu1 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "\n",
    "        self.layer2 = qnn.QuantConv2d(32, 32, 3, padding=1, bias=True, weight_bit_width=4, bias_quant=Int32Bias)\n",
    "        self.relu2 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "\n",
    "        self.layer3 = qnn.QuantConv2d(32, 64, 3, padding=1, bias=True, weight_bit_width=4, bias_quant=Int32Bias)\n",
    "        self.relu3 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "\n",
    "        self.layer4 = qnn.QuantConv2d(64, 64, 3, padding=1, bias=True, weight_bit_width=4, bias_quant=Int32Bias)\n",
    "        self.relu4 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "\n",
    "        self.layer5 = qnn.QuantConv2d(64, 64, 3, padding=1, bias=True, weight_bit_width=4, bias_quant=Int32Bias)\n",
    "        self.relu5 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "\n",
    "        self.fc1 = qnn.QuantLinear(64 * 8 * 8, 512, bias=True, weight_bit_width=4, bias_quant=Int32Bias)\n",
    "        self.relu6 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "\n",
    "        self.fc2 = qnn.QuantLinear(512, 10, bias=True, weight_bit_width=4, bias_quant=Int32Bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant_inp(x)\n",
    "        x = self.relu1(self.layer1(x))\n",
    "        x = self.relu2(self.layer2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = self.relu3(self.layer3(x))\n",
    "        x = self.relu4(self.layer4(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = self.relu5(self.layer5(x))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.relu6(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d93e3821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10CNN(\n",
      "  (quant_inp): QuantIdentity(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer1): QuantConv2d(\n",
      "    3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (relu1): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): QuantConv2d(\n",
      "    32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (relu2): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): QuantConv2d(\n",
      "    32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (relu3): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): QuantConv2d(\n",
      "    64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (relu4): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer5): QuantConv2d(\n",
      "    64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (relu5): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc1): QuantLinear(\n",
      "    in_features=4096, out_features=512, bias=True\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (relu6): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc2): QuantLinear(\n",
      "    in_features=512, out_features=10, bias=True\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Import testing\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Initialize the model, optimizer, and criterion\n",
    "model = CIFAR10CNN().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 80\n",
    "best_test_accuracy = 0\n",
    "patience = 10\n",
    "no_improvement_counter = 0\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b1a469",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b025142c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/80], Step [100/391], Loss: 1.8972\n",
      "Epoch [1/80], Step [200/391], Loss: 1.5202\n",
      "Epoch [1/80], Step [300/391], Loss: 1.7359\n",
      "Epoch [1/80], Test Accuracy: 49.24%, Precision: 0.52, Recall: 0.49, F1 score: 0.49\n",
      "Epoch [2/80], Step [100/391], Loss: 1.3538\n",
      "Epoch [2/80], Step [200/391], Loss: 1.1671\n",
      "Epoch [2/80], Step [300/391], Loss: 1.1206\n",
      "Epoch [2/80], Test Accuracy: 59.40%, Precision: 0.59, Recall: 0.59, F1 score: 0.57\n",
      "Epoch [3/80], Step [100/391], Loss: 1.1277\n",
      "Epoch [3/80], Step [200/391], Loss: 0.9731\n",
      "Epoch [3/80], Step [300/391], Loss: 1.0713\n",
      "Epoch [3/80], Test Accuracy: 64.78%, Precision: 0.64, Recall: 0.65, F1 score: 0.64\n",
      "Epoch [4/80], Step [100/391], Loss: 1.0216\n",
      "Epoch [4/80], Step [200/391], Loss: 0.9958\n",
      "Epoch [4/80], Step [300/391], Loss: 0.9228\n",
      "Epoch [4/80], Test Accuracy: 68.28%, Precision: 0.69, Recall: 0.68, F1 score: 0.68\n",
      "Epoch [5/80], Step [100/391], Loss: 0.8728\n",
      "Epoch [5/80], Step [200/391], Loss: 0.7728\n",
      "Epoch [5/80], Step [300/391], Loss: 0.7903\n",
      "Epoch [5/80], Test Accuracy: 69.16%, Precision: 0.72, Recall: 0.69, F1 score: 0.69\n",
      "Epoch [6/80], Step [100/391], Loss: 0.8310\n",
      "Epoch [6/80], Step [200/391], Loss: 0.6278\n",
      "Epoch [6/80], Step [300/391], Loss: 0.8112\n",
      "Epoch [6/80], Test Accuracy: 72.97%, Precision: 0.74, Recall: 0.73, F1 score: 0.73\n",
      "Epoch [7/80], Step [100/391], Loss: 0.8340\n",
      "Epoch [7/80], Step [200/391], Loss: 0.6697\n",
      "Epoch [7/80], Step [300/391], Loss: 0.6625\n",
      "Epoch [7/80], Test Accuracy: 75.62%, Precision: 0.76, Recall: 0.76, F1 score: 0.75\n",
      "Epoch [8/80], Step [100/391], Loss: 0.6959\n",
      "Epoch [8/80], Step [200/391], Loss: 0.8982\n",
      "Epoch [8/80], Step [300/391], Loss: 0.6457\n",
      "Epoch [8/80], Test Accuracy: 76.59%, Precision: 0.77, Recall: 0.77, F1 score: 0.76\n",
      "Epoch [9/80], Step [100/391], Loss: 0.9548\n",
      "Epoch [9/80], Step [200/391], Loss: 0.6848\n",
      "Epoch [9/80], Step [300/391], Loss: 0.6830\n",
      "Epoch [9/80], Test Accuracy: 77.31%, Precision: 0.78, Recall: 0.77, F1 score: 0.77\n",
      "Epoch [10/80], Step [100/391], Loss: 0.6331\n",
      "Epoch [10/80], Step [200/391], Loss: 0.6266\n",
      "Epoch [10/80], Step [300/391], Loss: 0.6538\n",
      "Epoch [10/80], Test Accuracy: 75.79%, Precision: 0.78, Recall: 0.76, F1 score: 0.76\n",
      "Epoch [11/80], Step [100/391], Loss: 0.4682\n",
      "Epoch [11/80], Step [200/391], Loss: 0.5816\n",
      "Epoch [11/80], Step [300/391], Loss: 0.6003\n",
      "Epoch [11/80], Test Accuracy: 77.00%, Precision: 0.78, Recall: 0.77, F1 score: 0.77\n",
      "Epoch [12/80], Step [100/391], Loss: 0.5006\n",
      "Epoch [12/80], Step [200/391], Loss: 0.5638\n",
      "Epoch [12/80], Step [300/391], Loss: 0.4871\n",
      "Epoch [12/80], Test Accuracy: 79.17%, Precision: 0.79, Recall: 0.79, F1 score: 0.79\n",
      "Epoch [13/80], Step [100/391], Loss: 0.5603\n",
      "Epoch [13/80], Step [200/391], Loss: 0.5132\n",
      "Epoch [13/80], Step [300/391], Loss: 0.6047\n",
      "Epoch [13/80], Test Accuracy: 79.23%, Precision: 0.80, Recall: 0.79, F1 score: 0.79\n",
      "Epoch [14/80], Step [100/391], Loss: 0.7397\n",
      "Epoch [14/80], Step [200/391], Loss: 0.6728\n",
      "Epoch [14/80], Step [300/391], Loss: 0.4926\n",
      "Epoch [14/80], Test Accuracy: 80.15%, Precision: 0.80, Recall: 0.80, F1 score: 0.80\n",
      "Epoch [15/80], Step [100/391], Loss: 0.4482\n",
      "Epoch [15/80], Step [200/391], Loss: 0.4772\n",
      "Epoch [15/80], Step [300/391], Loss: 0.5504\n",
      "Epoch [15/80], Test Accuracy: 80.08%, Precision: 0.80, Recall: 0.80, F1 score: 0.80\n",
      "Epoch [16/80], Step [100/391], Loss: 0.5537\n",
      "Epoch [16/80], Step [200/391], Loss: 0.3892\n",
      "Epoch [16/80], Step [300/391], Loss: 0.4650\n",
      "Epoch [16/80], Test Accuracy: 80.33%, Precision: 0.81, Recall: 0.80, F1 score: 0.80\n",
      "Epoch [17/80], Step [100/391], Loss: 0.4990\n",
      "Epoch [17/80], Step [200/391], Loss: 0.5263\n",
      "Epoch [17/80], Step [300/391], Loss: 0.3430\n",
      "Epoch [17/80], Test Accuracy: 81.23%, Precision: 0.81, Recall: 0.81, F1 score: 0.81\n",
      "Epoch [18/80], Step [100/391], Loss: 0.4229\n",
      "Epoch [18/80], Step [200/391], Loss: 0.4893\n",
      "Epoch [18/80], Step [300/391], Loss: 0.3536\n",
      "Epoch [18/80], Test Accuracy: 79.76%, Precision: 0.81, Recall: 0.80, F1 score: 0.80\n",
      "Epoch [19/80], Step [100/391], Loss: 0.4494\n",
      "Epoch [19/80], Step [200/391], Loss: 0.4275\n",
      "Epoch [19/80], Step [300/391], Loss: 0.3661\n",
      "Epoch [19/80], Test Accuracy: 81.27%, Precision: 0.81, Recall: 0.81, F1 score: 0.81\n",
      "Epoch [20/80], Step [100/391], Loss: 0.4436\n",
      "Epoch [20/80], Step [200/391], Loss: 0.3963\n",
      "Epoch [20/80], Step [300/391], Loss: 0.5763\n",
      "Epoch [20/80], Test Accuracy: 82.06%, Precision: 0.82, Recall: 0.82, F1 score: 0.82\n",
      "Epoch [21/80], Step [100/391], Loss: 0.3072\n",
      "Epoch [21/80], Step [200/391], Loss: 0.5457\n",
      "Epoch [21/80], Step [300/391], Loss: 0.5720\n",
      "Epoch [21/80], Test Accuracy: 80.76%, Precision: 0.81, Recall: 0.81, F1 score: 0.81\n",
      "Epoch [22/80], Step [100/391], Loss: 0.5189\n",
      "Epoch [22/80], Step [200/391], Loss: 0.5058\n",
      "Epoch [22/80], Step [300/391], Loss: 0.4491\n",
      "Epoch [22/80], Test Accuracy: 82.07%, Precision: 0.82, Recall: 0.82, F1 score: 0.82\n",
      "Epoch [23/80], Step [100/391], Loss: 0.5291\n",
      "Epoch [23/80], Step [200/391], Loss: 0.5069\n",
      "Epoch [23/80], Step [300/391], Loss: 0.3161\n",
      "Epoch [23/80], Test Accuracy: 82.54%, Precision: 0.83, Recall: 0.83, F1 score: 0.82\n",
      "Epoch [24/80], Step [100/391], Loss: 0.3994\n",
      "Epoch [24/80], Step [200/391], Loss: 0.5167\n",
      "Epoch [24/80], Step [300/391], Loss: 0.4673\n",
      "Epoch [24/80], Test Accuracy: 82.00%, Precision: 0.82, Recall: 0.82, F1 score: 0.82\n",
      "Epoch [25/80], Step [100/391], Loss: 0.3791\n",
      "Epoch [25/80], Step [200/391], Loss: 0.5111\n",
      "Epoch [25/80], Step [300/391], Loss: 0.3575\n",
      "Epoch [25/80], Test Accuracy: 82.49%, Precision: 0.83, Recall: 0.82, F1 score: 0.83\n",
      "Epoch [26/80], Step [100/391], Loss: 0.3440\n",
      "Epoch [26/80], Step [200/391], Loss: 0.4069\n",
      "Epoch [26/80], Step [300/391], Loss: 0.3996\n",
      "Epoch [26/80], Test Accuracy: 82.93%, Precision: 0.83, Recall: 0.83, F1 score: 0.83\n",
      "Epoch [27/80], Step [100/391], Loss: 0.4519\n",
      "Epoch [27/80], Step [200/391], Loss: 0.3987\n",
      "Epoch [27/80], Step [300/391], Loss: 0.3989\n",
      "Epoch [27/80], Test Accuracy: 81.85%, Precision: 0.82, Recall: 0.82, F1 score: 0.82\n",
      "Epoch [28/80], Step [100/391], Loss: 0.2774\n",
      "Epoch [28/80], Step [200/391], Loss: 0.4364\n",
      "Epoch [28/80], Step [300/391], Loss: 0.4359\n",
      "Epoch [28/80], Test Accuracy: 82.81%, Precision: 0.83, Recall: 0.83, F1 score: 0.83\n",
      "Epoch [29/80], Step [100/391], Loss: 0.3120\n",
      "Epoch [29/80], Step [200/391], Loss: 0.4190\n",
      "Epoch [29/80], Step [300/391], Loss: 0.2390\n",
      "Epoch [29/80], Test Accuracy: 81.06%, Precision: 0.82, Recall: 0.81, F1 score: 0.81\n",
      "Epoch [30/80], Step [100/391], Loss: 0.3729\n",
      "Epoch [30/80], Step [200/391], Loss: 0.6459\n",
      "Epoch [30/80], Step [300/391], Loss: 0.3836\n",
      "Epoch [30/80], Test Accuracy: 82.44%, Precision: 0.83, Recall: 0.82, F1 score: 0.82\n",
      "Epoch [31/80], Step [100/391], Loss: 0.4752\n",
      "Epoch [31/80], Step [200/391], Loss: 0.3455\n",
      "Epoch [31/80], Step [300/391], Loss: 0.3830\n",
      "Epoch [31/80], Test Accuracy: 82.76%, Precision: 0.83, Recall: 0.83, F1 score: 0.83\n",
      "Epoch [32/80], Step [100/391], Loss: 0.3770\n",
      "Epoch [32/80], Step [200/391], Loss: 0.3720\n",
      "Epoch [32/80], Step [300/391], Loss: 0.4283\n",
      "Epoch 00032: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch [32/80], Test Accuracy: 82.46%, Precision: 0.83, Recall: 0.82, F1 score: 0.82\n",
      "Epoch [33/80], Step [100/391], Loss: 0.2826\n",
      "Epoch [33/80], Step [200/391], Loss: 0.3584\n",
      "Epoch [33/80], Step [300/391], Loss: 0.2870\n",
      "Epoch [33/80], Test Accuracy: 84.71%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [34/80], Step [100/391], Loss: 0.3763\n",
      "Epoch [34/80], Step [200/391], Loss: 0.3055\n",
      "Epoch [34/80], Step [300/391], Loss: 0.3208\n",
      "Epoch [34/80], Test Accuracy: 85.07%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [35/80], Step [100/391], Loss: 0.2168\n",
      "Epoch [35/80], Step [200/391], Loss: 0.3195\n",
      "Epoch [35/80], Step [300/391], Loss: 0.3480\n",
      "Epoch [35/80], Test Accuracy: 85.14%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [36/80], Step [100/391], Loss: 0.3666\n",
      "Epoch [36/80], Step [200/391], Loss: 0.2694\n",
      "Epoch [36/80], Step [300/391], Loss: 0.2864\n",
      "Epoch [36/80], Test Accuracy: 84.97%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [37/80], Step [100/391], Loss: 0.3343\n",
      "Epoch [37/80], Step [200/391], Loss: 0.2621\n",
      "Epoch [37/80], Step [300/391], Loss: 0.2795\n",
      "Epoch [37/80], Test Accuracy: 85.23%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [38/80], Step [100/391], Loss: 0.1972\n",
      "Epoch [38/80], Step [200/391], Loss: 0.3318\n",
      "Epoch [38/80], Step [300/391], Loss: 0.2763\n",
      "Epoch [38/80], Test Accuracy: 85.32%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/80], Step [100/391], Loss: 0.2509\n",
      "Epoch [39/80], Step [200/391], Loss: 0.1989\n",
      "Epoch [39/80], Step [300/391], Loss: 0.2103\n",
      "Epoch [39/80], Test Accuracy: 85.40%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [40/80], Step [100/391], Loss: 0.2970\n",
      "Epoch [40/80], Step [200/391], Loss: 0.2483\n",
      "Epoch [40/80], Step [300/391], Loss: 0.2940\n",
      "Epoch [40/80], Test Accuracy: 85.17%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [41/80], Step [100/391], Loss: 0.3413\n",
      "Epoch [41/80], Step [200/391], Loss: 0.2039\n",
      "Epoch [41/80], Step [300/391], Loss: 0.3251\n",
      "Epoch [41/80], Test Accuracy: 84.93%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [42/80], Step [100/391], Loss: 0.2876\n",
      "Epoch [42/80], Step [200/391], Loss: 0.1971\n",
      "Epoch [42/80], Step [300/391], Loss: 0.2656\n",
      "Epoch [42/80], Test Accuracy: 84.87%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [43/80], Step [100/391], Loss: 0.2298\n",
      "Epoch [43/80], Step [200/391], Loss: 0.2188\n",
      "Epoch [43/80], Step [300/391], Loss: 0.2144\n",
      "Epoch [43/80], Test Accuracy: 85.04%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [44/80], Step [100/391], Loss: 0.3785\n",
      "Epoch [44/80], Step [200/391], Loss: 0.2457\n",
      "Epoch [44/80], Step [300/391], Loss: 0.2532\n",
      "Epoch 00044: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch [44/80], Test Accuracy: 85.00%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [45/80], Step [100/391], Loss: 0.1869\n",
      "Epoch [45/80], Step [200/391], Loss: 0.2049\n",
      "Epoch [45/80], Step [300/391], Loss: 0.2953\n",
      "Epoch [45/80], Test Accuracy: 85.47%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [46/80], Step [100/391], Loss: 0.2314\n",
      "Epoch [46/80], Step [200/391], Loss: 0.2638\n",
      "Epoch [46/80], Step [300/391], Loss: 0.3098\n",
      "Epoch [46/80], Test Accuracy: 85.18%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [47/80], Step [100/391], Loss: 0.2348\n",
      "Epoch [47/80], Step [200/391], Loss: 0.2250\n",
      "Epoch [47/80], Step [300/391], Loss: 0.2940\n",
      "Epoch [47/80], Test Accuracy: 85.26%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [48/80], Step [100/391], Loss: 0.3417\n",
      "Epoch [48/80], Step [200/391], Loss: 0.3215\n",
      "Epoch [48/80], Step [300/391], Loss: 0.2679\n",
      "Epoch [48/80], Test Accuracy: 85.32%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [49/80], Step [100/391], Loss: 0.2368\n",
      "Epoch [49/80], Step [200/391], Loss: 0.1329\n",
      "Epoch [49/80], Step [300/391], Loss: 0.2588\n",
      "Epoch [49/80], Test Accuracy: 85.44%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [50/80], Step [100/391], Loss: 0.3019\n",
      "Epoch [50/80], Step [200/391], Loss: 0.1812\n",
      "Epoch [50/80], Step [300/391], Loss: 0.2641\n",
      "Epoch [50/80], Test Accuracy: 85.45%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [51/80], Step [100/391], Loss: 0.2156\n",
      "Epoch [51/80], Step [200/391], Loss: 0.3037\n",
      "Epoch [51/80], Step [300/391], Loss: 0.4034\n",
      "Epoch [51/80], Test Accuracy: 85.39%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [52/80], Step [100/391], Loss: 0.2010\n",
      "Epoch [52/80], Step [200/391], Loss: 0.2487\n",
      "Epoch [52/80], Step [300/391], Loss: 0.3359\n",
      "Epoch [52/80], Test Accuracy: 85.22%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [53/80], Step [100/391], Loss: 0.2600\n",
      "Epoch [53/80], Step [200/391], Loss: 0.2152\n",
      "Epoch [53/80], Step [300/391], Loss: 0.2729\n",
      "Epoch [53/80], Test Accuracy: 85.42%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [54/80], Step [100/391], Loss: 0.2051\n",
      "Epoch [54/80], Step [200/391], Loss: 0.1639\n",
      "Epoch [54/80], Step [300/391], Loss: 0.2174\n",
      "Epoch [54/80], Test Accuracy: 85.23%, Precision: 0.85, Recall: 0.85, F1 score: 0.85\n",
      "Epoch [55/80], Step [100/391], Loss: 0.2699\n",
      "Epoch [55/80], Step [200/391], Loss: 0.2197\n",
      "Epoch [55/80], Step [300/391], Loss: 0.2895\n",
      "Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # training phase\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
    "    \n",
    "    # Initialize the validation loss\n",
    "    val_loss = 0\n",
    "    \n",
    "    # testing phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()  # accumulate the validation loss\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "    \n",
    "        val_loss /= len(val_loader)  # calculate the average validation loss\n",
    "    \n",
    "        # Update the learning rate using the validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        test_accuracy = 100 * correct / total\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='weighted')\n",
    "        \n",
    "        if test_accuracy > best_test_accuracy:\n",
    "            best_test_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            no_improvement_counter = 0\n",
    "        else:\n",
    "            no_improvement_counter += 1\n",
    "            \n",
    "        if no_improvement_counter >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        print('Epoch [{}/{}], Test Accuracy: {:.2f}%, Precision: {:.2f}, Recall: {:.2f}, F1 score: {:.2f}'.format(epoch+1, num_epochs, test_accuracy, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "defed63a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final best test accuracy is: 85.47% at Epoch: 55\n"
     ]
    }
   ],
   "source": [
    "# Print the best test accuracy\n",
    "print(\"The final best test accuracy is: {:.2f}% at Epoch: {}\".format(best_test_accuracy, epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1736e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[0.24959462 0.85064251 0.63611337]\n",
      " [0.21971782 0.76959296 0.85198825]\n",
      " [0.39966766 0.74227046 0.38671764]]\n",
      "[[ 5.10630528+0.j         -1.24968249-0.42234905j -1.24968249+0.42234905j]\n",
      " [ 0.0513731 -0.27075702j  0.21262735+0.30163319j -0.44429482+0.43664721j]\n",
      " [ 0.0513731 +0.27075702j -0.44429482-0.43664721j  0.21262735-0.30163319j]]\n",
      "[ 0.          0.33333333 -0.33333333]\n",
      "At loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashin\\AppData\\Local\\Temp\\ipykernel_22500\\1566019414.py:19: RuntimeWarning: divide by zero encountered in divide\n",
      "  filter_2D = 1/(np.sqrt(f[:None]**2 + f[None, :] ** 2)) ** gamma\n",
      "C:\\Users\\ashin\\AppData\\Local\\Temp\\ipykernel_22500\\1566019414.py:22: RuntimeWarning: invalid value encountered in multiply\n",
      "  filtered_fft = fft_result * filter_2D\n",
      "C:\\Users\\ashin\\AppData\\Local\\Temp\\ipykernel_22500\\1566019414.py:38: RuntimeWarning: invalid value encountered in greater\n",
      "  mask = ifft_result > T\n"
     ]
    }
   ],
   "source": [
    "def random_clust_mask(N, P, gamma):\n",
    "    \n",
    "    # Generate random NxN matrix with values between 0 and 1\n",
    "    matrix = np.random.rand(N, N)\n",
    "    \n",
    "    # Compute 2D FFTransform\n",
    "    fft_result = np.fft.fft2(matrix)\n",
    "    \n",
    "    # 1D Frequency Vector with N bins\n",
    "    f = np.fft.fftfreq(N)\n",
    "    \n",
    "    # Values for testing\n",
    "    print(matrix)\n",
    "    print(fft_result)\n",
    "    print(f)\n",
    "    \n",
    "    # Create a 2D filter in frequency space that varies inversely with freq over f\n",
    "    # Gamma controls the falloff rate\n",
    "    filter_2D = 1/(np.sqrt(f[:None]**2 + f[None, :] ** 2)) ** gamma\n",
    "    \n",
    "    # Mult the 2D elementwise by the filter\n",
    "    filtered_fft = fft_result * filter_2D\n",
    "    \n",
    "    # 2D inverse FFT of the filtered result\n",
    "    ifft_result = np.fft.ifft2(filtered_fft)\n",
    "    \n",
    "    # Set the threshold T equal the the max value in IFFT\n",
    "    T = ifft_result.max()\n",
    "    \n",
    "    # Init empty bool mask with same dims as ifft\n",
    "    mask = np.zeros_like(ifft_result, dtype=bool)\n",
    "    \n",
    "    print(\"At loop\")\n",
    "    \n",
    "    # Repeat until frac of nonzero values in the mask is greather than or equal to P\n",
    "    while np.count_nonzero(mask) / (N * N) < P:\n",
    "\n",
    "        mask = ifft_result > T\n",
    "        \n",
    "        # Decrease threshold incrementally\n",
    "        T -= 0.2\n",
    "    \n",
    "    # Return tensor\n",
    "    return torch.tensor(mask, dtype=torch.bool)\n",
    "\n",
    "\n",
    "def apply_mask_to_weights(layer, mask, P, gamma):\n",
    "    \n",
    "    # Get the size of the last dimension of layers weights\n",
    "    N = layer.weight.data.size(-1)\n",
    "    \n",
    "    # Generate random clustered mask using function above\n",
    "    mask = random_clust_mask(N, P, gamma)\n",
    "    \n",
    "    # Set the weights at the locations in mask to zero. \n",
    "    layer.weight.data[mask] = 0\n",
    "\n",
    "\n",
    "    \n",
    "# Testing\n",
    "print(model.layer1.weight.data.size(-1))\n",
    "\n",
    "print(random_clust_mask(model.layer1.weight.data.size(-1), 0.5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c4285b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
