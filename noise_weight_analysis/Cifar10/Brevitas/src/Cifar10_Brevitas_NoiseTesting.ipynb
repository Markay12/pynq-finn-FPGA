{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d262029f",
   "metadata": {},
   "source": [
    "## Loading Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab45e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import os\n",
    "from unicodedata import decimal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# add imports for randomness\n",
    "import time\n",
    "import random\n",
    "\n",
    "import sys\n",
    "\n",
    "# Brevitas imports\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.quant import Int32Bias\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# For adaptive learning rate import\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "## Imports from utils file for my defined noise functions\n",
    "import sys\n",
    "sys.path.append('C:/Users/ashin/source/repos/Cifar10_Pytorch_NoiseAnalysis/Cifar10_Pytorch_NoiseAnalysis/pynq-finn-FPGA/noise_weight_analysis/utils/')\n",
    "\n",
    "from noise_functions import add_digital_noise, random_clust_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b10c6b2",
   "metadata": {},
   "source": [
    "## Define Target Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85b627c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Target device: \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb176a",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Define the train and validation set sizes. Split dataset into train and validation sets.\n",
    "\n",
    "Set the batch size. Create a dataloader for a training dataset with batch size of 1000.\n",
    "\n",
    "### Data Augmentation\n",
    "\n",
    "This code block applies data augmentation to the CIFAR-10 training dataset using transforms.RandomCrop and transforms.RandomHorizontalFlip. This randomly crops and flips the images in the dataset, which creates new variations of the original images. This technique is called data augmentation and can help prevent overfitting by increasing the diversity of the training dataset.\n",
    "\n",
    "Additionally, this code block also normalizes the pixel values of both the training and validation datasets to have a mean of 0.5 and a standard deviation of 0.5 using transforms.Normalize.\n",
    "\n",
    "Furthermore, the code block uses PyTorch DataLoader to create an iterator over the dataset that returns batches of data. This avoids the need for manual batch creation and helps to efficiently load and process the data.\n",
    "\n",
    "Finally, this code block creates a DataLoader for the training and validation datasets with a batch size of 1000. This means that the model will process 1000 images at a time during training and validation, which can help to speed up the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae95b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "torch.Size([128, 3, 32, 32])\n",
      "50000\n",
      "Samples in each set: train = 50000, test = 391\n",
      "Shape of one input sample: torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define data augmentation transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Apply data augmentation to the training dataset\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "\n",
    "# Use the validation transform for the validation dataset\n",
    "val_set =torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=val_transform)\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "a = next(iter(train_loader))\n",
    "print(a[0].size())\n",
    "print(len(train_set))\n",
    "\n",
    "print(\"Samples in each set: train = %d, test = %s\" % (len(train_set), len(train_loader))) \n",
    "print(\"Shape of one input sample: \" +  str(train_set[0][0].shape))\n",
    "\n",
    "## Data Loader\n",
    "#\n",
    "# Using PyTorch dataloader we can create a convenient iterator over the dataset that returns batches of data, rather than requiring manual batch creation.\n",
    "\n",
    "# set batch size\n",
    "batch_size = 1000\n",
    "\n",
    "# Create a DataLoader for a training dataset with a batch size of 100\n",
    "train_quantized_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "test_quantized_loader = DataLoader(val_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be4e5f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Shape:\n",
      "-------------------------\n",
      "Input shape for 1 batch: torch.Size([128, 3, 32, 32])\n",
      "Label shape for 1 batch: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "print(\"\\nDataset Shape:\\n-------------------------\")\n",
    "for x, y in train_loader:\n",
    "    print(\"Input shape for 1 batch: \" + str(x.shape))\n",
    "    print(\"Label shape for 1 batch: \" + str(y.shape))\n",
    "    count += 1\n",
    "    if count == 1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53010ed9",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "\n",
    "There are 5 convolution layers and 2 Fully Connected QuantLinear Layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357e66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10CNN, self).__init__()\n",
    "        self.quant_inp = qnn.QuantIdentity(bit_width=4, return_quant_tensor=True)\n",
    "\n",
    "        self.layer1 = qnn.QuantConv2d(3, 32, 3, padding=1, bias=True, weight_bit_width=4, bias_quant=Int32Bias)\n",
    "        self.relu1 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "\n",
    "        self.layer2 = qnn.QuantConv2d(32, 32, 3, padding=1, bias=True, weight_bit_width=4, bias_quant=Int32Bias)\n",
    "        self.relu2 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "\n",
    "        self.layer3 = qnn.QuantConv2d(32, 64, 3, padding=1, bias=True, weight_bit_width=4, bias_quant=Int32Bias)\n",
    "        self.relu3 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "\n",
    "        self.layer4 = qnn.QuantConv2d(64, 64, 3, padding=1, bias=True, weight_bit_width=4, bias_quant=Int32Bias)\n",
    "        self.relu4 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "\n",
    "        self.layer5 = qnn.QuantConv2d(64, 64, 3, padding=1, bias=True, weight_bit_width=4, bias_quant=Int32Bias)\n",
    "        self.relu5 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "\n",
    "        self.fc1 = qnn.QuantLinear(64 * 8 * 8, 512, bias=True, weight_bit_width=4, bias_quant=Int32Bias)\n",
    "        self.relu6 = qnn.QuantReLU(bit_width=4, return_quant_tensor=True)\n",
    "\n",
    "        self.fc2 = qnn.QuantLinear(512, 10, bias=True, weight_bit_width=4, bias_quant=Int32Bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant_inp(x)\n",
    "        x = self.relu1(self.layer1(x))\n",
    "        x = self.relu2(self.layer2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = self.relu3(self.layer3(x))\n",
    "        x = self.relu4(self.layer4(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = self.relu5(self.layer5(x))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.relu6(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93e3821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10CNN(\n",
      "  (quant_inp): QuantIdentity(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): Identity()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer1): QuantConv2d(\n",
      "    3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (relu1): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): QuantConv2d(\n",
      "    32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (relu2): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): QuantConv2d(\n",
      "    32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (relu3): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): QuantConv2d(\n",
      "    64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (relu4): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer5): QuantConv2d(\n",
      "    64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (relu5): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc1): QuantLinear(\n",
      "    in_features=4096, out_features=512, bias=True\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (relu6): QuantReLU(\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (act_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "        (activation_impl): ReLU()\n",
      "        (tensor_quant): RescalingIntQuant(\n",
      "          (int_quant): IntQuant(\n",
      "            (float_to_int_impl): RoundSte()\n",
      "            (tensor_clamp_impl): TensorClamp()\n",
      "            (delay_wrapper): DelayWrapper(\n",
      "              (delay_impl): _NoDelay()\n",
      "            )\n",
      "          )\n",
      "          (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "            (stats_input_view_shape_impl): OverTensorView()\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsPercentile()\n",
      "            )\n",
      "            (restrict_scaling): _RestrictValue(\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (clamp_scaling): _ClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "            )\n",
      "            (restrict_inplace_preprocess): Identity()\n",
      "            (restrict_preprocess): Identity()\n",
      "          )\n",
      "          (int_scaling_impl): IntScaling()\n",
      "          (zero_point_impl): ZeroZeroPoint(\n",
      "            (zero_point): StatelessBuffer()\n",
      "          )\n",
      "          (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "            (bit_width): StatelessBuffer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc2): QuantLinear(\n",
      "    in_features=512, out_features=10, bias=True\n",
      "    (input_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (output_quant): ActQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "    )\n",
      "    (weight_quant): WeightQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClampSte()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): StatsFromParameterScaling(\n",
      "          (parameter_list_stats): _ParameterListStats(\n",
      "            (first_tracked_param): _ViewParameterWrapper(\n",
      "              (view_shape_impl): OverTensorView()\n",
      "            )\n",
      "            (stats): _Stats(\n",
      "              (stats_impl): AbsMax()\n",
      "            )\n",
      "          )\n",
      "          (stats_scaling_impl): _StatsScaling(\n",
      "            (affine_rescaling): Identity()\n",
      "            (restrict_clamp_scaling): _RestrictClampValue(\n",
      "              (clamp_min_ste): ScalarClampMinSte()\n",
      "              (restrict_value_impl): FloatRestrictValue()\n",
      "            )\n",
      "            (restrict_scaling_pre): Identity()\n",
      "          )\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bias_quant): BiasQuantProxyFromInjector(\n",
      "      (_zero_hw_sentinel): StatelessBuffer()\n",
      "      (tensor_quant): PrescaledRestrictIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "        (zero_point): StatelessBuffer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Import testing\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Initialize the model, optimizer, and criterion\n",
    "model = CIFAR10CNN().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 80\n",
    "best_test_accuracy = 0\n",
    "patience = 4\n",
    "no_improvement_counter = 0\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b1a469",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b025142c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/80], Step [100/391], Loss: 1.8353\n",
      "Epoch [1/80], Step [200/391], Loss: 1.6892\n",
      "Epoch [1/80], Step [300/391], Loss: 1.4895\n",
      "Epoch [1/80], Test Accuracy: 48.35%, Precision: 0.50, Recall: 0.48, F1 score: 0.47\n",
      "Epoch [2/80], Step [100/391], Loss: 1.3974\n",
      "Epoch [2/80], Step [200/391], Loss: 1.3293\n",
      "Epoch [2/80], Step [300/391], Loss: 1.0691\n",
      "Epoch [2/80], Test Accuracy: 58.50%, Precision: 0.58, Recall: 0.58, F1 score: 0.58\n",
      "Epoch [3/80], Step [100/391], Loss: 1.4546\n",
      "Epoch [3/80], Step [200/391], Loss: 1.4877\n",
      "Epoch [3/80], Step [300/391], Loss: 1.2133\n",
      "Epoch [3/80], Test Accuracy: 63.14%, Precision: 0.63, Recall: 0.63, F1 score: 0.63\n",
      "Epoch [4/80], Step [100/391], Loss: 1.1304\n",
      "Epoch [4/80], Step [200/391], Loss: 0.9296\n",
      "Epoch [4/80], Step [300/391], Loss: 0.9632\n",
      "Epoch [4/80], Test Accuracy: 65.24%, Precision: 0.66, Recall: 0.65, F1 score: 0.65\n",
      "Epoch [5/80], Step [100/391], Loss: 1.0766\n",
      "Epoch [5/80], Step [200/391], Loss: 0.9853\n",
      "Epoch [5/80], Step [300/391], Loss: 1.1555\n",
      "Epoch [5/80], Test Accuracy: 68.66%, Precision: 0.68, Recall: 0.69, F1 score: 0.68\n",
      "Epoch [6/80], Step [100/391], Loss: 0.9770\n",
      "Epoch [6/80], Step [200/391], Loss: 0.8558\n",
      "Epoch [6/80], Step [300/391], Loss: 0.6618\n",
      "Epoch [6/80], Test Accuracy: 71.63%, Precision: 0.72, Recall: 0.72, F1 score: 0.71\n",
      "Epoch [7/80], Step [100/391], Loss: 0.8329\n",
      "Epoch [7/80], Step [200/391], Loss: 0.7231\n",
      "Epoch [7/80], Step [300/391], Loss: 0.9512\n",
      "Epoch [7/80], Test Accuracy: 73.68%, Precision: 0.73, Recall: 0.74, F1 score: 0.73\n",
      "Epoch [8/80], Step [100/391], Loss: 0.6472\n",
      "Epoch [8/80], Step [200/391], Loss: 0.7908\n",
      "Epoch [8/80], Step [300/391], Loss: 0.8065\n",
      "Epoch [8/80], Test Accuracy: 74.74%, Precision: 0.75, Recall: 0.75, F1 score: 0.74\n",
      "Epoch [9/80], Step [100/391], Loss: 0.5830\n",
      "Epoch [9/80], Step [200/391], Loss: 0.5445\n",
      "Epoch [9/80], Step [300/391], Loss: 0.8217\n",
      "Epoch [9/80], Test Accuracy: 74.90%, Precision: 0.76, Recall: 0.75, F1 score: 0.75\n",
      "Epoch [10/80], Step [100/391], Loss: 0.7685\n",
      "Epoch [10/80], Step [200/391], Loss: 0.8031\n",
      "Epoch [10/80], Step [300/391], Loss: 0.6400\n",
      "Epoch [10/80], Test Accuracy: 75.24%, Precision: 0.76, Recall: 0.75, F1 score: 0.75\n",
      "Epoch [11/80], Step [100/391], Loss: 0.5450\n",
      "Epoch [11/80], Step [200/391], Loss: 0.5758\n",
      "Epoch [11/80], Step [300/391], Loss: 0.6251\n",
      "Epoch [11/80], Test Accuracy: 77.13%, Precision: 0.77, Recall: 0.77, F1 score: 0.77\n",
      "Epoch [12/80], Step [100/391], Loss: 0.5563\n",
      "Epoch [12/80], Step [200/391], Loss: 0.7586\n",
      "Epoch [12/80], Step [300/391], Loss: 0.6350\n",
      "Epoch [12/80], Test Accuracy: 77.62%, Precision: 0.78, Recall: 0.78, F1 score: 0.77\n",
      "Epoch [13/80], Step [100/391], Loss: 0.6287\n",
      "Epoch [13/80], Step [200/391], Loss: 0.6703\n",
      "Epoch [13/80], Step [300/391], Loss: 0.6267\n",
      "Epoch [13/80], Test Accuracy: 77.88%, Precision: 0.78, Recall: 0.78, F1 score: 0.78\n",
      "Epoch [14/80], Step [100/391], Loss: 0.7219\n",
      "Epoch [14/80], Step [200/391], Loss: 0.5078\n",
      "Epoch [14/80], Step [300/391], Loss: 0.6511\n",
      "Epoch [14/80], Test Accuracy: 79.60%, Precision: 0.79, Recall: 0.80, F1 score: 0.79\n",
      "Epoch [15/80], Step [100/391], Loss: 0.6218\n",
      "Epoch [15/80], Step [200/391], Loss: 0.4678\n",
      "Epoch [15/80], Step [300/391], Loss: 0.8382\n",
      "Epoch [15/80], Test Accuracy: 80.02%, Precision: 0.80, Recall: 0.80, F1 score: 0.80\n",
      "Epoch [16/80], Step [100/391], Loss: 0.5101\n",
      "Epoch [16/80], Step [200/391], Loss: 0.5730\n",
      "Epoch [16/80], Step [300/391], Loss: 0.5225\n",
      "Epoch [16/80], Test Accuracy: 79.40%, Precision: 0.80, Recall: 0.79, F1 score: 0.79\n",
      "Epoch [17/80], Step [100/391], Loss: 0.5758\n",
      "Epoch [17/80], Step [200/391], Loss: 0.6022\n",
      "Epoch [17/80], Step [300/391], Loss: 0.3569\n",
      "Epoch [17/80], Test Accuracy: 80.54%, Precision: 0.81, Recall: 0.81, F1 score: 0.80\n",
      "Epoch [18/80], Step [100/391], Loss: 0.6162\n",
      "Epoch [18/80], Step [200/391], Loss: 0.6577\n",
      "Epoch [18/80], Step [300/391], Loss: 0.6047\n",
      "Epoch [18/80], Test Accuracy: 80.18%, Precision: 0.81, Recall: 0.80, F1 score: 0.80\n",
      "Epoch [19/80], Step [100/391], Loss: 0.5073\n",
      "Epoch [19/80], Step [200/391], Loss: 0.6323\n",
      "Epoch [19/80], Step [300/391], Loss: 0.5912\n",
      "Epoch [19/80], Test Accuracy: 79.68%, Precision: 0.80, Recall: 0.80, F1 score: 0.80\n",
      "Epoch [20/80], Step [100/391], Loss: 0.4867\n",
      "Epoch [20/80], Step [200/391], Loss: 0.4760\n",
      "Epoch [20/80], Step [300/391], Loss: 0.3361\n",
      "Epoch [20/80], Test Accuracy: 81.19%, Precision: 0.82, Recall: 0.81, F1 score: 0.81\n",
      "Epoch [21/80], Step [100/391], Loss: 0.4234\n",
      "Epoch [21/80], Step [200/391], Loss: 0.5463\n",
      "Epoch [21/80], Step [300/391], Loss: 0.5704\n",
      "Epoch [21/80], Test Accuracy: 80.47%, Precision: 0.81, Recall: 0.80, F1 score: 0.80\n",
      "Epoch [22/80], Step [100/391], Loss: 0.4114\n",
      "Epoch [22/80], Step [200/391], Loss: 0.5182\n",
      "Epoch [22/80], Step [300/391], Loss: 0.5981\n",
      "Epoch [22/80], Test Accuracy: 81.06%, Precision: 0.81, Recall: 0.81, F1 score: 0.81\n",
      "Epoch [23/80], Step [100/391], Loss: 0.5125\n",
      "Epoch [23/80], Step [200/391], Loss: 0.6289\n",
      "Epoch [23/80], Step [300/391], Loss: 0.5791\n",
      "Epoch [23/80], Test Accuracy: 81.09%, Precision: 0.82, Recall: 0.81, F1 score: 0.81\n",
      "Epoch [24/80], Step [100/391], Loss: 0.4034\n",
      "Epoch [24/80], Step [200/391], Loss: 0.3720\n",
      "Epoch [24/80], Step [300/391], Loss: 0.4530\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # training phase\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
    "    \n",
    "    # Initialize the validation loss\n",
    "    val_loss = 0\n",
    "    \n",
    "    # testing phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()  # accumulate the validation loss\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "    \n",
    "        val_loss /= len(val_loader)  # calculate the average validation loss\n",
    "    \n",
    "        # Update the learning rate using the validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        test_accuracy = 100 * correct / total\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='weighted')\n",
    "        \n",
    "        if test_accuracy > best_test_accuracy:\n",
    "            best_test_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            no_improvement_counter = 0\n",
    "        else:\n",
    "            no_improvement_counter += 1\n",
    "            \n",
    "        if no_improvement_counter >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        print('Epoch [{}/{}], Test Accuracy: {:.2f}%, Precision: {:.2f}, Recall: {:.2f}, F1 score: {:.2f}'.format(epoch+1, num_epochs, test_accuracy, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "defed63a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final best test accuracy is: 81.19% at Epoch: 24\n"
     ]
    }
   ],
   "source": [
    "# Print the best test accuracy\n",
    "print(\"The final best test accuracy is: {:.2f}% at Epoch: {}\".format(best_test_accuracy, epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbfed0df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m P \u001b[38;5;241m=\u001b[39m P_values[i]\n\u001b[0;32m     14\u001b[0m G \u001b[38;5;241m=\u001b[39m gamma_values[i]\n\u001b[1;32m---> 15\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_clust_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m ax\u001b[38;5;241m.\u001b[39mimshow(mask, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbability = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Gamma = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(P, G))\n",
      "File \u001b[1;32mC:\\Users/ashin/source/repos/Cifar10_Pytorch_NoiseAnalysis/Cifar10_Pytorch_NoiseAnalysis/pynq-finn-FPGA/noise_weight_analysis/utils\\noise_functions.py:35\u001b[0m, in \u001b[0;36mrandom_clust_mask\u001b[1;34m(weight_shape, P, gamma)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandom_clust_mask\u001b[39m(weight_shape, P, gamma):\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Generate random NxN matrix with values between 0 and 1\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     N \u001b[38;5;241m=\u001b[39m \u001b[43mweight_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     36\u001b[0m     matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(N, N)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Compute 2D FFT\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing\n",
    "N = model.layer1.weight.data.size(-1)\n",
    "\n",
    "# Create a 2x3 grid of subplots\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10, 6))\n",
    "\n",
    "# Generate masks with different values for P\n",
    "P_values = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.5, 0.75, 1]\n",
    "gamma_values = [1e-3, 0.1, 0.1, 0.5, 0.75, 0.99, 1, 1.5, 2]\n",
    "\n",
    "# Loop over subplots and generate mask for each value of P\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    P = P_values[i]\n",
    "    G = gamma_values[i]\n",
    "    mask = random_clust_mask(64, P, G)\n",
    "    ax.imshow(mask, cmap='gray')\n",
    "    ax.set_title(\"Probability = {}, Gamma = {}\".format(P, G))\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d4daf19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(6):\\n    ber = 10 ** (-8+i)\\n    noisy_matrix = add_digital_noise(matrix, ber)\\n    print(f\"BER = {ber:.1e}:\\n{noisy_matrix}\\n\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(time.time())\n",
    "\n",
    "# Testing function with a sweep from 1e-8 to 1e-3\n",
    "matrix = np.random.rand(3, 3) * 2 - 1\n",
    "\n",
    "\"\"\"\n",
    "for i in range(6):\n",
    "    ber = 10 ** (-8+i)\n",
    "    noisy_matrix = add_digital_noise(matrix, ber)\n",
    "    print(f\"BER = {ber:.1e}:\\n{noisy_matrix}\\n\")\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef69a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Noise\n",
    "\n",
    "trained_state_dict = model.state_dict()\n",
    "\n",
    "def test(model, test_loader):\n",
    "    # testing phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def random_clust_mask(weight_shape, P, gamma):\n",
    "\n",
    "    # Generate random NxN matrix with values between 0 and 1\n",
    "    N = weight_shape[-1]\n",
    "    matrix = np.random.rand(N, N)\n",
    "\n",
    "    # Compute 2D FFT\n",
    "    fft_result = np.fft.fft2(matrix)\n",
    "\n",
    "    # 1D Frequency Vector with N bins\n",
    "    f = np.fft.fftfreq(N, d=1.0/weight_shape[-1])\n",
    "    f_x, f_y = np.meshgrid(f, f)\n",
    "    f_x[0, 0] = 1e-6\n",
    "    f_y[0, 0] = 1e-6\n",
    "\n",
    "    # Create a 2D filter in frequency space that varies inversely with freq over f\n",
    "    # Gamma controls the falloff rate\n",
    "    filter_2D = 1/(np.sqrt(f_x**2 + f_y**2))**gamma\n",
    "\n",
    "    # Mult the 2D elementwise by the filter\n",
    "    filtered_fft = fft_result * filter_2D\n",
    "\n",
    "    # 2D inverse FFT of the filtered result\n",
    "    ifft_result = np.fft.ifft2(filtered_fft)\n",
    "    ifft_result = np.real(ifft_result)\n",
    "\n",
    "    # Set the threshold T equal the the max value in IFFT\n",
    "    T = ifft_result.max()\n",
    "\n",
    "    # Init empty bool mask with same dims as ifft\n",
    "    mask = np.zeros_like(ifft_result, dtype=bool)\n",
    "\n",
    "    decrement_step = 0.01\n",
    "\n",
    "    # Repeat until frac of nonzero values in the mask is greater than or equal to P\n",
    "    while True:\n",
    "        mask = ifft_result > T\n",
    "\n",
    "        current_fraction = np.count_nonzero(mask) / (N * N)\n",
    "\n",
    "        if current_fraction >= P:\n",
    "            break\n",
    "\n",
    "        T -= decrement_step\n",
    "\n",
    "    # Return tensor with the same shape as the input tensor\n",
    "    mask = np.tile(mask, (weight_shape[0], weight_shape[1], 1, 1))\n",
    "    return torch.tensor(mask, dtype=torch.float)\n",
    "\n",
    "\n",
    "def add_mask_to_model_brevitas(model, layer_names, p, gamma, num_perturbations):\n",
    "\n",
    "    modified_models = []\n",
    "\n",
    "    for _ in range(num_perturbations):\n",
    "\n",
    "        modified_model = deepcopy(model)\n",
    "\n",
    "        for layer_name in layer_names:\n",
    "\n",
    "            layer = getattr(modified_model, layer_name)\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                # get weights and biases of the tensors\n",
    "                weight = layer.weight.cpu().detach().numpy()\n",
    "                bias = layer.bias.cpu().detach().numpy() if layer.bias is not None else None\n",
    "\n",
    "                # get number of output channels of layer\n",
    "                out_channels = layer.out_channels\n",
    "\n",
    "                # generate mask with correct shape\n",
    "                mask = random_clust_mask(weight.shape, p, gamma)\n",
    "\n",
    "                # convert weight tensor to PyTorch tensor\n",
    "                weight_tensor = torch.tensor(weight, dtype=torch.float)\n",
    "\n",
    "                # apply mask to the whole weight tensor\n",
    "                weight_tensor *= torch.tensor(mask, dtype=torch.float)\n",
    "\n",
    "                # create new weight parameter and assign to layer\n",
    "                noised_weight = torch.nn.Parameter(weight_tensor, requires_grad=False)\n",
    "                layer.weight = noised_weight\n",
    "\n",
    "        modified_models.append(modified_model)\n",
    "\n",
    "    return modified_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bce2aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Perturbations for Layer 1:\n",
      "P Value:  0.1 , Gamma Value:  0.1  Average Accuracy:  12.45 %\n",
      "P Value:  0.5 , Gamma Value:  0.5  Average Accuracy:  44.732 %\n",
      "P Value:  1.0 , Gamma Value:  1.0  Average Accuracy:  81.18 %\n"
     ]
    }
   ],
   "source": [
    "pvals = [0.1, 0.5, 1.0]\n",
    "gammavals = [0.1, 0.5, 1.0]\n",
    "\n",
    "from noise_functions import test, add_mask_to_model_brevitas, random_clust_mask\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    # testing phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "layers = ['layer1']\n",
    "\n",
    "num_perturbations = 5\n",
    "\n",
    "print(\"\\nTesting Perturbations for Layer 1:\")\n",
    "\n",
    "for p in range(len(pvals)):\n",
    "    \n",
    "    noisy_models = add_mask_to_model_brevitas(model, layers, pvals[p], gammavals[p], num_perturbations)\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for noisy_model in noisy_models:\n",
    "        \n",
    "        noisy_model.to(device)\n",
    "        accuracies.append(test(noisy_model, test_quantized_loader, device))\n",
    "        \n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    \n",
    "    print(\"P Value: \", pvals[p], \", Gamma Value: \", gammavals[p], \" Average Accuracy: \", avg_accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb90b6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Perturbations for Layer 1 with Digital Noise:\n",
      "Ber:  1e-06  Average Accuracy:  81.18 %\n",
      "Ber:  1e-05  Average Accuracy:  81.18 %\n",
      "Ber:  0.0001  Average Accuracy:  81.18 %\n",
      "Ber:  0.001  Average Accuracy:  80.012 %\n",
      "Ber:  0.01  Average Accuracy:  73.934 %\n",
      "Ber:  0.1  Average Accuracy:  39.354 %\n"
     ]
    }
   ],
   "source": [
    "def add_digital_noise_to_model_brevitas(model, layer_names, ber, num_perturbations):\n",
    "    \n",
    "    modified_models = []\n",
    "    \n",
    "    for _ in range(num_perturbations):\n",
    "        \n",
    "        modified_model = deepcopy(model)\n",
    "        \n",
    "        for layer_name in layer_names:\n",
    "            \n",
    "            layer = getattr(modified_model, layer_name)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                \n",
    "                weight = layer.weight.cpu().detach().numpy()\n",
    "                noisy_weight = add_digital_noise(weight, ber)\n",
    "                \n",
    "                \n",
    "                layer.weight = torch.nn.Parameter(torch.tensor(noisy_weight, dtype=torch.float))\n",
    "                \n",
    "        modified_models.append(modified_model)\n",
    "        \n",
    "    return modified_models\n",
    "\n",
    "\n",
    "# Test add digital noise with BER\n",
    "\n",
    "bers = [1e-6, 1e-5, 1e-4, 1e-3, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "layers = ['layer1']\n",
    "\n",
    "num_perturbations = 5\n",
    "\n",
    "print(\"\\nTesting Perturbations for Layer 1 with Digital Noise:\")\n",
    "\n",
    "for b in range(len(bers)):\n",
    "    \n",
    "    noisy_models = add_digital_noise_to_model_brevitas(model, layers, bers[b], num_perturbations)\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for noisy_model in noisy_models:\n",
    "        \n",
    "        noisy_model.to(device)\n",
    "        accuracies.append(test(noisy_model, test_quantized_loader, device))\n",
    "        \n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    \n",
    "    print(\"Ber: \", bers[b], \" Average Accuracy: \", avg_accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a807392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
