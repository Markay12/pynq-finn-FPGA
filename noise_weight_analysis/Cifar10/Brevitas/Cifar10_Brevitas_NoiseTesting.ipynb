{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b359aa01",
   "metadata": {},
   "source": [
    "## Loading Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa56bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import os\n",
    "from unicodedata import decimal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# add imports for randomness\n",
    "import time\n",
    "import random\n",
    "\n",
    "import sys\n",
    "\n",
    "# Brevitas imports\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.quant import Int32Bias\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# For adaptive learning rate import\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from multiprocessing import freeze_support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bda7a9c",
   "metadata": {},
   "source": [
    "## Define Target Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe38dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Target device: \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b453ccd7",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Define the train and validation set sizes. Split dataset into train and validation sets.\n",
    "\n",
    "Set the batch size. Create a dataloader for a training dataset with batch size of 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0dae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
